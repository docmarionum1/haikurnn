{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense, Dropout, LSTM, Embedding, Reshape, Input, InputLayer, Concatenate, Lambda, Add\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/docmario/miniconda3/envs/haiku/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0_syllables</th>\n",
       "      <th>1_syllables</th>\n",
       "      <th>2_syllables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Memorial Day --</td>\n",
       "      <td>a shadow for each</td>\n",
       "      <td>white cross</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spring rain -</td>\n",
       "      <td>as the doctor speaks</td>\n",
       "      <td>i think of lilacs</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spring rain -</td>\n",
       "      <td>as the doctor speaks</td>\n",
       "      <td>i think of lilacs</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spring moonset --</td>\n",
       "      <td>a rice ball for</td>\n",
       "      <td>breakfast</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spring moonset --</td>\n",
       "      <td>a rice ball for</td>\n",
       "      <td>breakfast</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sunny afternoon</td>\n",
       "      <td>an old man lingers</td>\n",
       "      <td>near the mailbox</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cinco de mayo</td>\n",
       "      <td>horses roll</td>\n",
       "      <td>in the shallows</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>quitting time</td>\n",
       "      <td>the smell of rain</td>\n",
       "      <td>in the lobby</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>waves</td>\n",
       "      <td>slowly cresting towards shore</td>\n",
       "      <td>a faint moon</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>waves</td>\n",
       "      <td>slowly cresting towards shore</td>\n",
       "      <td>a faint moon</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>overnight rain --</td>\n",
       "      <td>the scent of orange blossoms</td>\n",
       "      <td>in a desert town</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>misty summer rain</td>\n",
       "      <td>calling pheasant</td>\n",
       "      <td>in Zen temple</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>day is done</td>\n",
       "      <td>poppies amidst</td>\n",
       "      <td>the dying grass</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>watching clouds</td>\n",
       "      <td>the white petals</td>\n",
       "      <td>of a crushed crocus</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mountain stream</td>\n",
       "      <td>two well placed rocks</td>\n",
       "      <td>the path home</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>night shift--</td>\n",
       "      <td>in the parking lot car lights</td>\n",
       "      <td>dim near morning</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>a wild violet</td>\n",
       "      <td>on the sunny hill~</td>\n",
       "      <td>noon time nap</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>a wild violet</td>\n",
       "      <td>on the sunny hill~</td>\n",
       "      <td>noon time nap</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>a sunny day</td>\n",
       "      <td>pink haze of the cherry blossoms</td>\n",
       "      <td>over the hill</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>polished oak --</td>\n",
       "      <td>the freesia's shadow ends</td>\n",
       "      <td>in coffee foam</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>nobody here</td>\n",
       "      <td>a table in the mountain</td>\n",
       "      <td>speckled with petals</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>first date</td>\n",
       "      <td>not even noticing</td>\n",
       "      <td>the new moon</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>vanishing difference . . .</td>\n",
       "      <td>gliding geese settle onto</td>\n",
       "      <td>their reflections</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>vanishing difference . . .</td>\n",
       "      <td>gliding geese settle onto</td>\n",
       "      <td>their reflections</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>distant hawk</td>\n",
       "      <td>a gust of cherry petals</td>\n",
       "      <td>crosses the lawn</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Orange sunrise peaks through</td>\n",
       "      <td>The tubes and wires of father's</td>\n",
       "      <td>Life support machine</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Orange sunrise peaks through</td>\n",
       "      <td>The tubes and wires of father's</td>\n",
       "      <td>Life support machine</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>moonlessness--</td>\n",
       "      <td>so many ways</td>\n",
       "      <td>I want to touch you</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>earth day--</td>\n",
       "      <td>even the shadows at dusk</td>\n",
       "      <td>smell green</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>so cold -</td>\n",
       "      <td>a goose honks its way</td>\n",
       "      <td>across the night sky</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21213</th>\n",
       "      <td>turquoise doors and trim</td>\n",
       "      <td>seem less hopeful since fading</td>\n",
       "      <td>peeling have set it</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21214</th>\n",
       "      <td>chair working to keep</td>\n",
       "      <td>door open no way to know</td>\n",
       "      <td>why it would matter</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21215</th>\n",
       "      <td>one hell of a step</td>\n",
       "      <td>and an arrow plus yellow</td>\n",
       "      <td>underground parking</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21216</th>\n",
       "      <td>minimalism</td>\n",
       "      <td>of blues blending together</td>\n",
       "      <td>respite from winter</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21217</th>\n",
       "      <td>the ad hoc groupings</td>\n",
       "      <td>oddly formal arrangement</td>\n",
       "      <td>pleasant to observe</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21218</th>\n",
       "      <td>delicate versions</td>\n",
       "      <td>of previous vibrant shades</td>\n",
       "      <td>desert sun at work</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21219</th>\n",
       "      <td>excellent arrow</td>\n",
       "      <td>term of highest praise  applies</td>\n",
       "      <td>to this example</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21220</th>\n",
       "      <td>pacific islands</td>\n",
       "      <td>airport security is</td>\n",
       "      <td>lovely in this light</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21221</th>\n",
       "      <td>wait what happened here</td>\n",
       "      <td>three shots and in color too</td>\n",
       "      <td>i hope im ok</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21222</th>\n",
       "      <td>weathered wooded cross</td>\n",
       "      <td>anchored by bits of color</td>\n",
       "      <td>and a bunch of rocks</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21223</th>\n",
       "      <td>this arrangement of</td>\n",
       "      <td>crosses at a grave looks like</td>\n",
       "      <td>a wrought iron crown</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21224</th>\n",
       "      <td>obligatory</td>\n",
       "      <td>iris  must post at least one</td>\n",
       "      <td>shot every springtime</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21224</th>\n",
       "      <td>obligatory</td>\n",
       "      <td>iris  must post at least one</td>\n",
       "      <td>shot every springtime</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21225</th>\n",
       "      <td>blonde madonna guards</td>\n",
       "      <td>graves her calm patient face a</td>\n",
       "      <td>respite from it all</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21226</th>\n",
       "      <td>night lights at grave site</td>\n",
       "      <td>comfort the living the dead</td>\n",
       "      <td>may not have noticed</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21227</th>\n",
       "      <td>hotel courtyard  nice</td>\n",
       "      <td>place to relax when summer sun</td>\n",
       "      <td>is too much for you</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21228</th>\n",
       "      <td>lavender midnight</td>\n",
       "      <td>blue: who says deserts are just</td>\n",
       "      <td>a single color</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21229</th>\n",
       "      <td>postcard views are real</td>\n",
       "      <td>making a long trip worth the</td>\n",
       "      <td>effort that it took</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21230</th>\n",
       "      <td>holiday motel</td>\n",
       "      <td>nice not expensive  wifi</td>\n",
       "      <td>kitchens and much more</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21231</th>\n",
       "      <td>wavy lines somehow</td>\n",
       "      <td>make pointed shadows something</td>\n",
       "      <td>i cant figure out</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21232</th>\n",
       "      <td>he gave up wearing</td>\n",
       "      <td>neckties when he retired but</td>\n",
       "      <td>kept them anyway</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21232</th>\n",
       "      <td>he gave up wearing</td>\n",
       "      <td>neckties when he retired but</td>\n",
       "      <td>kept them anyway</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21233</th>\n",
       "      <td>no words can enhance</td>\n",
       "      <td>the south pacific night time</td>\n",
       "      <td>skies why even try</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21234</th>\n",
       "      <td>rusts lovely colors</td>\n",
       "      <td>patterns can only mask the</td>\n",
       "      <td>certain destruction</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21235</th>\n",
       "      <td>on this site winning</td>\n",
       "      <td>warriors ate their enemies</td>\n",
       "      <td>seasoned with breadfruit</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21235</th>\n",
       "      <td>on this site winning</td>\n",
       "      <td>warriors ate their enemies</td>\n",
       "      <td>seasoned with breadfruit</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21236</th>\n",
       "      <td>eerie glow from night</td>\n",
       "      <td>divers undulates through the</td>\n",
       "      <td>clear ocean water</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21237</th>\n",
       "      <td>a desolate place</td>\n",
       "      <td>i stood on the porch to watch</td>\n",
       "      <td>the road it felt right</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21238</th>\n",
       "      <td>the day breaks gently</td>\n",
       "      <td>this close to the equator</td>\n",
       "      <td>days nights are equal</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21239</th>\n",
       "      <td>abandoned drive-in</td>\n",
       "      <td>lit by the glow of pink light</td>\n",
       "      <td>from a waning day</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25187 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  0                                 1  \\\n",
       "0                   Memorial Day --                 a shadow for each   \n",
       "1                     spring rain -              as the doctor speaks   \n",
       "1                     spring rain -              as the doctor speaks   \n",
       "2                 spring moonset --                   a rice ball for   \n",
       "2                 spring moonset --                   a rice ball for   \n",
       "3                   sunny afternoon                an old man lingers   \n",
       "4                     cinco de mayo                       horses roll   \n",
       "5                     quitting time                 the smell of rain   \n",
       "6                             waves     slowly cresting towards shore   \n",
       "6                             waves     slowly cresting towards shore   \n",
       "7                 overnight rain --      the scent of orange blossoms   \n",
       "8                 misty summer rain                  calling pheasant   \n",
       "9                       day is done                    poppies amidst   \n",
       "10                  watching clouds                  the white petals   \n",
       "11                  mountain stream             two well placed rocks   \n",
       "12                    night shift--     in the parking lot car lights   \n",
       "13                    a wild violet                on the sunny hill~   \n",
       "13                    a wild violet                on the sunny hill~   \n",
       "14                      a sunny day  pink haze of the cherry blossoms   \n",
       "15                  polished oak --         the freesia's shadow ends   \n",
       "16                      nobody here           a table in the mountain   \n",
       "17                       first date                 not even noticing   \n",
       "18       vanishing difference . . .         gliding geese settle onto   \n",
       "18       vanishing difference . . .         gliding geese settle onto   \n",
       "19                     distant hawk           a gust of cherry petals   \n",
       "20     Orange sunrise peaks through   The tubes and wires of father's   \n",
       "20     Orange sunrise peaks through   The tubes and wires of father's   \n",
       "21                   moonlessness--                      so many ways   \n",
       "22                      earth day--          even the shadows at dusk   \n",
       "23                        so cold -             a goose honks its way   \n",
       "...                             ...                               ...   \n",
       "21213      turquoise doors and trim    seem less hopeful since fading   \n",
       "21214         chair working to keep          door open no way to know   \n",
       "21215            one hell of a step          and an arrow plus yellow   \n",
       "21216                    minimalism        of blues blending together   \n",
       "21217          the ad hoc groupings          oddly formal arrangement   \n",
       "21218             delicate versions        of previous vibrant shades   \n",
       "21219               excellent arrow   term of highest praise  applies   \n",
       "21220               pacific islands               airport security is   \n",
       "21221       wait what happened here      three shots and in color too   \n",
       "21222        weathered wooded cross         anchored by bits of color   \n",
       "21223           this arrangement of     crosses at a grave looks like   \n",
       "21224                    obligatory      iris  must post at least one   \n",
       "21224                    obligatory      iris  must post at least one   \n",
       "21225         blonde madonna guards    graves her calm patient face a   \n",
       "21226    night lights at grave site       comfort the living the dead   \n",
       "21227         hotel courtyard  nice    place to relax when summer sun   \n",
       "21228             lavender midnight   blue: who says deserts are just   \n",
       "21229       postcard views are real      making a long trip worth the   \n",
       "21230                 holiday motel          nice not expensive  wifi   \n",
       "21231            wavy lines somehow    make pointed shadows something   \n",
       "21232            he gave up wearing      neckties when he retired but   \n",
       "21232            he gave up wearing      neckties when he retired but   \n",
       "21233          no words can enhance      the south pacific night time   \n",
       "21234           rusts lovely colors        patterns can only mask the   \n",
       "21235          on this site winning        warriors ate their enemies   \n",
       "21235          on this site winning        warriors ate their enemies   \n",
       "21236         eerie glow from night      divers undulates through the   \n",
       "21237              a desolate place     i stood on the porch to watch   \n",
       "21238         the day breaks gently         this close to the equator   \n",
       "21239            abandoned drive-in     lit by the glow of pink light   \n",
       "\n",
       "                              2 0_syllables 1_syllables 2_syllables  \n",
       "0                   white cross           5           5           2  \n",
       "1             i think of lilacs           2           5           5  \n",
       "1             i think of lilacs           3           5           5  \n",
       "2                     breakfast           3           4           2  \n",
       "2                     breakfast           4           4           2  \n",
       "3              near the mailbox           5           5           4  \n",
       "4               in the shallows           5           3           4  \n",
       "5                  in the lobby           3           4           4  \n",
       "6                  a faint moon           1           6           3  \n",
       "6                  a faint moon           1           7           3  \n",
       "7              in a desert town           4           7           5  \n",
       "8                 in Zen temple           5           4           4  \n",
       "9               the dying grass           3           4           4  \n",
       "10          of a crushed crocus           3           4           5  \n",
       "11                the path home           3           4           3  \n",
       "12             dim near morning           2           7           4  \n",
       "13                noon time nap           4           5           3  \n",
       "13                noon time nap           5           5           3  \n",
       "14                over the hill           4           8           4  \n",
       "15               in coffee foam           3           7           4  \n",
       "16         speckled with petals           4           7           5  \n",
       "17                 the new moon           2           6           3  \n",
       "18            their reflections           5           7           4  \n",
       "18            their reflections           6           7           4  \n",
       "19             crosses the lawn           3           7           4  \n",
       "20         Life support machine           6           8           5  \n",
       "20         Life support machine           6           7           5  \n",
       "21          I want to touch you           3           4           5  \n",
       "22                  smell green           2           7           2  \n",
       "23         across the night sky           2           5           5  \n",
       "...                         ...         ...         ...         ...  \n",
       "21213       peeling have set it           5           7           5  \n",
       "21214       why it would matter           5           7           5  \n",
       "21215       underground parking           5           7           5  \n",
       "21216       respite from winter           5           7           5  \n",
       "21217       pleasant to observe           5           7           5  \n",
       "21218        desert sun at work           5           7           5  \n",
       "21219           to this example           5           7           5  \n",
       "21220      lovely in this light           5           7           5  \n",
       "21221              i hope im ok           5           7           5  \n",
       "21222      and a bunch of rocks           5           7           5  \n",
       "21223      a wrought iron crown           5           7           5  \n",
       "21224     shot every springtime           5           7           5  \n",
       "21224     shot every springtime           5           7           6  \n",
       "21225       respite from it all           5           7           5  \n",
       "21226      may not have noticed           5           7           5  \n",
       "21227       is too much for you           5           8           5  \n",
       "21228            a single color           5           7           5  \n",
       "21229       effort that it took           5           7           5  \n",
       "21230    kitchens and much more           5           7           5  \n",
       "21231         i cant figure out           5           7           5  \n",
       "21232          kept them anyway           5           8           5  \n",
       "21232          kept them anyway           5           7           5  \n",
       "21233        skies why even try           5           7           5  \n",
       "21234       certain destruction           5           7           5  \n",
       "21235  seasoned with breadfruit           5           8           5  \n",
       "21235  seasoned with breadfruit           5           7           5  \n",
       "21236         clear ocean water           5           7           5  \n",
       "21237    the road it felt right           5           7           5  \n",
       "21238     days nights are equal           5           7           5  \n",
       "21239         from a waning day           4           7           5  \n",
       "\n",
       "[25187 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([\n",
    "    pd.read_csv('../input/poems/haikus_with_syllables.csv', encoding='latin1'),\n",
    "    pd.read_csv('../input/poems/haikus_sballas8_with_syllables.csv', encoding='latin1'),\n",
    "    pd.read_csv('../input/poems/haiku_unim.csv', encoding='latin1')\n",
    "]).reset_index(drop=True)\n",
    "df = df[df['lang'] == 'en'].copy()\n",
    "df = df[~pd.isnull(df['0']) & ~pd.isnull(df['1']) & ~pd.isnull(df['2'])].copy()\n",
    "df = df[~pd.isnull(df['0_syllables']) & ~pd.isnull(df['1_syllables']) & ~pd.isnull(df['2_syllables'])].copy()\n",
    "\n",
    "# Duplicate lines with ambiguous syllable counts\n",
    "lines = set([0, 1, 2])\n",
    "\n",
    "for i in range(3):\n",
    "    lines.remove(i)\n",
    "    df = df[[\n",
    "        '0', '1', '2',\n",
    "        #'1_syllables', '2_syllables'\n",
    "    ] + ['%s_syllables' % j for j in lines]].join(\n",
    "        df['%s_syllables' % i].str.split(\n",
    "            ',', expand=True\n",
    "        ).stack(-1).reset_index(\n",
    "            level=1, drop=True\n",
    "        ).rename('%s_syllables' % i)\n",
    "    ).drop_duplicates()\n",
    "    lines.add(i)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/docmario/miniconda3/envs/haiku/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/docmario/miniconda3/envs/haiku/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "max_line_len = int(max([df['%s' % i].str.len().quantile(.99) for i in range(3)]))\n",
    "df = df[\n",
    "    (df['0'].str.len() <= max_line_len) & \n",
    "    (df['1'].str.len() <= max_line_len) & \n",
    "    (df['2'].str.len() <= max_line_len)\n",
    "]\n",
    "\n",
    "for i in range(3):\n",
    "    #i = str(i)\n",
    "    df['%s_in' % i] = df[str(i)].str[0] + df[str(i)].str.pad(max_line_len, 'right', '\\n')\n",
    "    df['%s_out' % i] = df[str(i)].str.pad(max_line_len, 'right', '\\n') + ('\\n' if i == 2 else df[str(i+1)].str[0])\n",
    "    #df['%s_out' % i] = df[str(i)] + ('\\n' if i == 2 else df[str(i+1)].str[0])\n",
    "    #df['%s_out' % i] = df['%s_out' % i].str.pad(max_line_len + 1, 'right', '\\n')\n",
    "    \n",
    "max_line_len += 1\n",
    "\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = df[['0_in', '1_in', '2_in']].values\n",
    "\n",
    "t = Tokenizer(filters='', char_level=True)\n",
    "t.fit_on_texts(inputs.flatten())\n",
    "n_tokens = len(t.word_counts) + 1\n",
    "\n",
    "X = np_utils.to_categorical([\n",
    "    t.texts_to_sequences(inputs[:,i]) for i in range(3)\n",
    "], num_classes=n_tokens)\n",
    "\n",
    "outputs = df[['0_out', '1_out', '2_out']].values\n",
    "\n",
    "#t = Tokenizer(filters='', char_level=True)\n",
    "#t.fit_on_texts(outputs.flatten())\n",
    "Y = np_utils.to_categorical([\n",
    "    t.texts_to_sequences(outputs[:,i]) for i in range(3)\n",
    "], num_classes=n_tokens)\n",
    "\n",
    "n_tokens = len(t.word_counts) + 1\n",
    "\n",
    "X_syllables = df[['0_syllables', '1_syllables', '2_syllables']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "Layer (type)                                                      Output Shape                                Param #                 Connected to                                                      \n",
      "========================================================================================================================================================================================================\n",
      "syllables_line_0 (InputLayer)                                     (None, 1)                                   0                                                                                         \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "input_line_0 (InputLayer)                                         (None, None, 64)                            0                                                                                         \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "syllable_dense_0 (Dense)                                          (None, 512)                                 1024                    syllables_line_0[0][0]                                            \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "syllables_line_1 (InputLayer)                                     (None, 1)                                   0                                                                                         \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "lstm_0 (LSTM)                                                     [(None, None, 512), (None, 512), (None, 512 1181696                 input_line_0[0][0]                                                \n",
      "                                                                                                                                      syllable_dense_0[0][0]                                            \n",
      "                                                                                                                                      syllable_dense_0[0][0]                                            \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "syllable_dense_1 (Dense)                                          (None, 512)                                 1024                    syllables_line_1[0][0]                                            \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "input_line_1 (InputLayer)                                         (None, None, 64)                            0                                                                                         \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "add_h_1 (Add)                                                     (None, 512)                                 0                       lstm_0[0][1]                                                      \n",
      "                                                                                                                                      syllable_dense_1[0][0]                                            \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "add_c_1 (Add)                                                     (None, 512)                                 0                       lstm_0[0][2]                                                      \n",
      "                                                                                                                                      syllable_dense_1[0][0]                                            \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "syllables_line_2 (InputLayer)                                     (None, 1)                                   0                                                                                         \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                                                     [(None, None, 512), (None, 512), (None, 512 1181696                 input_line_1[0][0]                                                \n",
      "                                                                                                                                      add_h_1[0][0]                                                     \n",
      "                                                                                                                                      add_c_1[0][0]                                                     \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "syllable_dense_2 (Dense)                                          (None, 512)                                 1024                    syllables_line_2[0][0]                                            \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "input_line_2 (InputLayer)                                         (None, None, 64)                            0                                                                                         \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "add_h_2 (Add)                                                     (None, 512)                                 0                       lstm_1[0][1]                                                      \n",
      "                                                                                                                                      syllable_dense_2[0][0]                                            \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "add_c_2 (Add)                                                     (None, 512)                                 0                       lstm_1[0][2]                                                      \n",
      "                                                                                                                                      syllable_dense_2[0][0]                                            \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                                                     [(None, None, 512), (None, 512), (None, 512 1181696                 input_line_2[0][0]                                                \n",
      "                                                                                                                                      add_h_2[0][0]                                                     \n",
      "                                                                                                                                      add_c_2[0][0]                                                     \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "output_0 (Dense)                                                  (None, None, 64)                            32832                   lstm_0[0][0]                                                      \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "output_1 (Dense)                                                  (None, None, 64)                            32832                   lstm_1[0][0]                                                      \n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "output_2 (Dense)                                                  (None, None, 64)                            32832                   lstm_2[0][0]                                                      \n",
      "========================================================================================================================================================================================================\n",
      "Total params: 3,646,656\n",
      "Trainable params: 3,646,656\n",
      "Non-trainable params: 0\n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 512\n",
    "\n",
    "# Keras Model\n",
    "\n",
    "inputs = [Input(shape=(None, n_tokens), name='input_line_%s' % i) for i in range(3)]\n",
    "\n",
    "syllables = [Input(shape=(1,), name='syllables_line_%s' % i) for i in range(3)]\n",
    "syllable_denses = [Dense(latent_dim, activation='relu', name='syllable_dense_%s' % i) for i in range(3)]\n",
    "syllable_dense_outputs = [syllable_denses[i](syllables[i]) for i in range(3)]\n",
    "\n",
    "lstms = [LSTM(latent_dim, return_state=True, return_sequences=True, name='lstm_%s' % i) for i in range(3)]\n",
    "\n",
    "lstm_out, lstm_h, lstm_c = [None, None, None], [None, None, None], [None, None, None]\n",
    "for i in range(3):\n",
    "    if i > 0:\n",
    "        lstm_out[i], lstm_h[i], lstm_c[i] = lstms[i](inputs[i], initial_state=[\n",
    "            Add(name='add_h_%s' % i)([\n",
    "                lstm_h[i-1],\n",
    "                syllable_dense_outputs[i]\n",
    "            ]),\n",
    "            Add(name='add_c_%s' % i)([\n",
    "                lstm_c[i-1],\n",
    "                syllable_dense_outputs[i]\n",
    "            ])\n",
    "        ])\n",
    "    else:\n",
    "        lstm_out[i], lstm_h[i], lstm_c[i] = lstms[i](inputs[i], initial_state=[\n",
    "            syllable_dense_outputs[i], syllable_dense_outputs[i]\n",
    "        ])\n",
    "        \n",
    "denses = [Dense(n_tokens, activation='softmax', name='output_%s' % i) for i in range(3)]\n",
    "outputs = [denses[i](lstm_out[i]) for i in range(3)]\n",
    "\n",
    "# Enforce number of chars per line\n",
    "#counter = Lambda(lambda x: K.sum(K.cast(K.less(K.argmax(x, axis=2), 60), K.floatx()), axis=1, keepdims=True))\n",
    "#counts = [counter(i) for i in outputs]\n",
    "\n",
    "#model = Model(inputs, outputs + counts)\n",
    "\n",
    "model = Model(inputs + syllables, outputs)\n",
    "\n",
    "# Use categorical for the character outputs and MSE for the counts\n",
    "#model.compile(optimizer='rmsprop', loss=['categorical_crossentropy']*3 + ['mean_squared_error']*3)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model.summary(line_length=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  7, 21, 10,  9,  8, 17,  2, 10,  5,  9,  8,  2, 25,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(X[0][1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "24777/24777 [==============================] - 344s 14ms/step - loss: 1.3306 - output_0_loss: 0.4516 - output_1_loss: 0.5081 - output_2_loss: 0.3709\n",
      "Epoch 2/1000\n",
      "24777/24777 [==============================] - 416s 17ms/step - loss: 1.2727 - output_0_loss: 0.4332 - output_1_loss: 0.4883 - output_2_loss: 0.3511\n",
      "Epoch 3/1000\n",
      "24777/24777 [==============================] - 436s 18ms/step - loss: 1.2187 - output_0_loss: 0.4165 - output_1_loss: 0.4701 - output_2_loss: 0.3322\n",
      "Epoch 4/1000\n",
      "24777/24777 [==============================] - 472s 19ms/step - loss: 1.1673 - output_0_loss: 0.3999 - output_1_loss: 0.4530 - output_2_loss: 0.3144\n",
      "Epoch 5/1000\n",
      "24777/24777 [==============================] - 448s 18ms/step - loss: 1.1179 - output_0_loss: 0.3842 - output_1_loss: 0.4364 - output_2_loss: 0.2973\n",
      "Epoch 6/1000\n",
      "24777/24777 [==============================] - 446s 18ms/step - loss: 1.0719 - output_0_loss: 0.3693 - output_1_loss: 0.4207 - output_2_loss: 0.2820\n",
      "Epoch 7/1000\n",
      "24777/24777 [==============================] - 436s 18ms/step - loss: 1.0280 - output_0_loss: 0.3549 - output_1_loss: 0.4058 - output_2_loss: 0.2673\n",
      "Epoch 8/1000\n",
      "24777/24777 [==============================] - 438s 18ms/step - loss: 0.9873 - output_0_loss: 0.3414 - output_1_loss: 0.3919 - output_2_loss: 0.2540\n",
      "Epoch 9/1000\n",
      "24777/24777 [==============================] - 428s 17ms/step - loss: 0.9491 - output_0_loss: 0.3292 - output_1_loss: 0.3782 - output_2_loss: 0.2417\n",
      "Epoch 10/1000\n",
      "24777/24777 [==============================] - 438s 18ms/step - loss: 0.9132 - output_0_loss: 0.3178 - output_1_loss: 0.3650 - output_2_loss: 0.2303\n",
      "Epoch 11/1000\n",
      "24777/24777 [==============================] - 427s 17ms/step - loss: 0.8807 - output_0_loss: 0.3071 - output_1_loss: 0.3534 - output_2_loss: 0.2202\n",
      "Epoch 12/1000\n",
      "24777/24777 [==============================] - 437s 18ms/step - loss: 0.8504 - output_0_loss: 0.2974 - output_1_loss: 0.3423 - output_2_loss: 0.2107\n",
      "Epoch 13/1000\n",
      "24777/24777 [==============================] - 431s 17ms/step - loss: 0.8224 - output_0_loss: 0.2883 - output_1_loss: 0.3318 - output_2_loss: 0.2023\n",
      "Epoch 14/1000\n",
      "24777/24777 [==============================] - 436s 18ms/step - loss: 0.7969 - output_0_loss: 0.2803 - output_1_loss: 0.3225 - output_2_loss: 0.1942\n",
      "Epoch 15/1000\n",
      "24777/24777 [==============================] - 432s 17ms/step - loss: 0.7728 - output_0_loss: 0.2728 - output_1_loss: 0.3134 - output_2_loss: 0.1867\n",
      "Epoch 16/1000\n",
      "24777/24777 [==============================] - 440s 18ms/step - loss: 0.7511 - output_0_loss: 0.2661 - output_1_loss: 0.3049 - output_2_loss: 0.1802\n",
      "Epoch 17/1000\n",
      "24777/24777 [==============================] - 438s 18ms/step - loss: 0.7304 - output_0_loss: 0.2595 - output_1_loss: 0.2971 - output_2_loss: 0.1737\n",
      "Epoch 18/1000\n",
      "24777/24777 [==============================] - 436s 18ms/step - loss: 0.7122 - output_0_loss: 0.2540 - output_1_loss: 0.2899 - output_2_loss: 0.1683\n",
      "Epoch 19/1000\n",
      "24777/24777 [==============================] - 428s 17ms/step - loss: 0.6941 - output_0_loss: 0.2482 - output_1_loss: 0.2831 - output_2_loss: 0.1628\n",
      "Epoch 20/1000\n",
      "24777/24777 [==============================] - 446s 18ms/step - loss: 0.6783 - output_0_loss: 0.2434 - output_1_loss: 0.2768 - output_2_loss: 0.1580\n",
      "Epoch 21/1000\n",
      "24777/24777 [==============================] - 433s 17ms/step - loss: 0.6633 - output_0_loss: 0.2392 - output_1_loss: 0.2709 - output_2_loss: 0.1532\n",
      "Epoch 22/1000\n",
      "24777/24777 [==============================] - 432s 17ms/step - loss: 0.6487 - output_0_loss: 0.2346 - output_1_loss: 0.2655 - output_2_loss: 0.1486\n",
      "Epoch 23/1000\n",
      "24777/24777 [==============================] - 432s 17ms/step - loss: 0.6357 - output_0_loss: 0.2310 - output_1_loss: 0.2599 - output_2_loss: 0.1448\n",
      "Epoch 24/1000\n",
      "24777/24777 [==============================] - 428s 17ms/step - loss: 0.6241 - output_0_loss: 0.2277 - output_1_loss: 0.2555 - output_2_loss: 0.1408\n",
      "Epoch 25/1000\n",
      "24777/24777 [==============================] - 444s 18ms/step - loss: 0.6127 - output_0_loss: 0.2243 - output_1_loss: 0.2508 - output_2_loss: 0.1376\n",
      "Epoch 26/1000\n",
      "24777/24777 [==============================] - 433s 17ms/step - loss: 0.6019 - output_0_loss: 0.2211 - output_1_loss: 0.2465 - output_2_loss: 0.1343\n",
      "Epoch 27/1000\n",
      "24777/24777 [==============================] - 418s 17ms/step - loss: 0.5924 - output_0_loss: 0.2184 - output_1_loss: 0.2426 - output_2_loss: 0.1314\n",
      "Epoch 28/1000\n",
      "24777/24777 [==============================] - 436s 18ms/step - loss: 0.5830 - output_0_loss: 0.2159 - output_1_loss: 0.2388 - output_2_loss: 0.1284\n",
      "Epoch 29/1000\n",
      "24777/24777 [==============================] - 439s 18ms/step - loss: 0.5738 - output_0_loss: 0.2130 - output_1_loss: 0.2352 - output_2_loss: 0.1256\n",
      "Epoch 30/1000\n",
      "24777/24777 [==============================] - 429s 17ms/step - loss: 0.5651 - output_0_loss: 0.2106 - output_1_loss: 0.2319 - output_2_loss: 0.1226\n",
      "Epoch 31/1000\n",
      "24777/24777 [==============================] - 437s 18ms/step - loss: 0.5573 - output_0_loss: 0.2084 - output_1_loss: 0.2286 - output_2_loss: 0.1202\n",
      "Epoch 32/1000\n",
      "24777/24777 [==============================] - 431s 17ms/step - loss: 0.5499 - output_0_loss: 0.2063 - output_1_loss: 0.2256 - output_2_loss: 0.1180\n",
      "Epoch 33/1000\n",
      "24777/24777 [==============================] - 439s 18ms/step - loss: 0.5422 - output_0_loss: 0.2045 - output_1_loss: 0.2225 - output_2_loss: 0.1153\n",
      "Epoch 34/1000\n",
      "24777/24777 [==============================] - 420s 17ms/step - loss: 0.5354 - output_0_loss: 0.2024 - output_1_loss: 0.2198 - output_2_loss: 0.1132\n",
      "Epoch 35/1000\n",
      "24777/24777 [==============================] - 434s 18ms/step - loss: 0.5290 - output_0_loss: 0.2006 - output_1_loss: 0.2170 - output_2_loss: 0.1113\n",
      "Epoch 36/1000\n",
      "24777/24777 [==============================] - 432s 17ms/step - loss: 0.5228 - output_0_loss: 0.1991 - output_1_loss: 0.2143 - output_2_loss: 0.1093\n",
      "Epoch 37/1000\n",
      "24777/24777 [==============================] - 433s 17ms/step - loss: 0.5151 - output_0_loss: 0.1968 - output_1_loss: 0.2112 - output_2_loss: 0.1072\n",
      "Epoch 38/1000\n",
      "24777/24777 [==============================] - 432s 17ms/step - loss: 0.5109 - output_0_loss: 0.1959 - output_1_loss: 0.2094 - output_2_loss: 0.1056\n",
      "Epoch 39/1000\n",
      "24777/24777 [==============================] - 433s 17ms/step - loss: 0.5049 - output_0_loss: 0.1945 - output_1_loss: 0.2071 - output_2_loss: 0.1033\n",
      "Epoch 40/1000\n",
      "24777/24777 [==============================] - 433s 17ms/step - loss: 0.4999 - output_0_loss: 0.1929 - output_1_loss: 0.2049 - output_2_loss: 0.1021\n",
      "Epoch 41/1000\n",
      "24777/24777 [==============================] - 435s 18ms/step - loss: 0.4948 - output_0_loss: 0.1917 - output_1_loss: 0.2029 - output_2_loss: 0.1003\n",
      "Epoch 42/1000\n",
      "24777/24777 [==============================] - 440s 18ms/step - loss: 0.4897 - output_0_loss: 0.1904 - output_1_loss: 0.2006 - output_2_loss: 0.0987\n",
      "Epoch 43/1000\n",
      "24777/24777 [==============================] - 434s 18ms/step - loss: 0.4847 - output_0_loss: 0.1890 - output_1_loss: 0.1986 - output_2_loss: 0.0970\n",
      "Epoch 44/1000\n",
      "24777/24777 [==============================] - 427s 17ms/step - loss: 0.4806 - output_0_loss: 0.1878 - output_1_loss: 0.1969 - output_2_loss: 0.0959\n",
      "Epoch 45/1000\n",
      "24777/24777 [==============================] - 434s 17ms/step - loss: 0.4760 - output_0_loss: 0.1866 - output_1_loss: 0.1951 - output_2_loss: 0.0943\n",
      "Epoch 46/1000\n",
      "24777/24777 [==============================] - 428s 17ms/step - loss: 0.4724 - output_0_loss: 0.1853 - output_1_loss: 0.1936 - output_2_loss: 0.0934\n",
      "Epoch 47/1000\n",
      "24777/24777 [==============================] - 440s 18ms/step - loss: 0.4679 - output_0_loss: 0.1846 - output_1_loss: 0.1916 - output_2_loss: 0.0917\n",
      "Epoch 48/1000\n",
      "24777/24777 [==============================] - 424s 17ms/step - loss: 0.4635 - output_0_loss: 0.1835 - output_1_loss: 0.1900 - output_2_loss: 0.0901\n",
      "Epoch 49/1000\n",
      "24777/24777 [==============================] - 439s 18ms/step - loss: 0.4598 - output_0_loss: 0.1825 - output_1_loss: 0.1883 - output_2_loss: 0.0891\n",
      "Epoch 50/1000\n",
      "24777/24777 [==============================] - 435s 18ms/step - loss: 0.4566 - output_0_loss: 0.1816 - output_1_loss: 0.1868 - output_2_loss: 0.0881\n",
      "Epoch 51/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24777/24777 [==============================] - 433s 17ms/step - loss: 0.4528 - output_0_loss: 0.1805 - output_1_loss: 0.1854 - output_2_loss: 0.0869\n",
      "Epoch 52/1000\n",
      "24777/24777 [==============================] - 431s 17ms/step - loss: 0.4499 - output_0_loss: 0.1801 - output_1_loss: 0.1841 - output_2_loss: 0.0857\n",
      "Epoch 53/1000\n",
      "24777/24777 [==============================] - 450s 18ms/step - loss: 0.4455 - output_0_loss: 0.1790 - output_1_loss: 0.1822 - output_2_loss: 0.0843\n",
      "Epoch 54/1000\n",
      "24777/24777 [==============================] - 428s 17ms/step - loss: 0.4423 - output_0_loss: 0.1779 - output_1_loss: 0.1809 - output_2_loss: 0.0834\n",
      "Epoch 55/1000\n",
      "24777/24777 [==============================] - 445s 18ms/step - loss: 0.4398 - output_0_loss: 0.1772 - output_1_loss: 0.1796 - output_2_loss: 0.0830\n",
      "Epoch 56/1000\n",
      "24777/24777 [==============================] - 434s 18ms/step - loss: 0.4360 - output_0_loss: 0.1767 - output_1_loss: 0.1779 - output_2_loss: 0.0814\n",
      "Epoch 57/1000\n",
      "24777/24777 [==============================] - 437s 18ms/step - loss: 0.4324 - output_0_loss: 0.1752 - output_1_loss: 0.1765 - output_2_loss: 0.0807\n",
      "Epoch 58/1000\n",
      "24777/24777 [==============================] - 430s 17ms/step - loss: 0.4292 - output_0_loss: 0.1747 - output_1_loss: 0.1751 - output_2_loss: 0.0794\n",
      "Epoch 59/1000\n",
      "24777/24777 [==============================] - 434s 18ms/step - loss: 0.4269 - output_0_loss: 0.1739 - output_1_loss: 0.1744 - output_2_loss: 0.0787\n",
      "Epoch 60/1000\n",
      "24777/24777 [==============================] - 445s 18ms/step - loss: 0.4238 - output_0_loss: 0.1732 - output_1_loss: 0.1729 - output_2_loss: 0.0778\n",
      "Epoch 61/1000\n",
      "24777/24777 [==============================] - 420s 17ms/step - loss: 0.4215 - output_0_loss: 0.1728 - output_1_loss: 0.1719 - output_2_loss: 0.0769\n",
      "Epoch 62/1000\n",
      "24777/24777 [==============================] - 434s 18ms/step - loss: 0.4186 - output_0_loss: 0.1720 - output_1_loss: 0.1705 - output_2_loss: 0.0760\n",
      "Epoch 63/1000\n",
      "24777/24777 [==============================] - 442s 18ms/step - loss: 0.4154 - output_0_loss: 0.1713 - output_1_loss: 0.1691 - output_2_loss: 0.0751\n",
      "Epoch 64/1000\n",
      "24777/24777 [==============================] - 438s 18ms/step - loss: 0.4133 - output_0_loss: 0.1704 - output_1_loss: 0.1687 - output_2_loss: 0.0743\n",
      "Epoch 65/1000\n",
      "24777/24777 [==============================] - 433s 17ms/step - loss: 0.4103 - output_0_loss: 0.1697 - output_1_loss: 0.1672 - output_2_loss: 0.0735\n",
      "Epoch 66/1000\n",
      "24777/24777 [==============================] - 442s 18ms/step - loss: 0.4075 - output_0_loss: 0.1689 - output_1_loss: 0.1655 - output_2_loss: 0.0731\n",
      "Epoch 67/1000\n",
      "24777/24777 [==============================] - 439s 18ms/step - loss: 0.4056 - output_0_loss: 0.1685 - output_1_loss: 0.1648 - output_2_loss: 0.0723\n",
      "Epoch 68/1000\n",
      "24777/24777 [==============================] - 433s 17ms/step - loss: 0.4026 - output_0_loss: 0.1677 - output_1_loss: 0.1635 - output_2_loss: 0.0715\n",
      "Epoch 69/1000\n",
      "24777/24777 [==============================] - 441s 18ms/step - loss: 0.4004 - output_0_loss: 0.1670 - output_1_loss: 0.1626 - output_2_loss: 0.0708\n",
      "Epoch 70/1000\n",
      "24777/24777 [==============================] - 426s 17ms/step - loss: 0.3988 - output_0_loss: 0.1667 - output_1_loss: 0.1621 - output_2_loss: 0.0700\n",
      "Epoch 71/1000\n",
      "24777/24777 [==============================] - 443s 18ms/step - loss: 0.3966 - output_0_loss: 0.1662 - output_1_loss: 0.1608 - output_2_loss: 0.0696\n",
      "Epoch 72/1000\n",
      "24777/24777 [==============================] - 426s 17ms/step - loss: 0.3942 - output_0_loss: 0.1655 - output_1_loss: 0.1599 - output_2_loss: 0.0689\n",
      "Epoch 73/1000\n",
      "24777/24777 [==============================] - 432s 17ms/step - loss: 0.3916 - output_0_loss: 0.1647 - output_1_loss: 0.1588 - output_2_loss: 0.0680\n",
      "Epoch 74/1000\n",
      "24777/24777 [==============================] - 444s 18ms/step - loss: 0.3900 - output_0_loss: 0.1642 - output_1_loss: 0.1582 - output_2_loss: 0.0676\n",
      "Epoch 75/1000\n",
      "24777/24777 [==============================] - 420s 17ms/step - loss: 0.3882 - output_0_loss: 0.1639 - output_1_loss: 0.1571 - output_2_loss: 0.0672\n",
      "Epoch 76/1000\n",
      "24777/24777 [==============================] - 443s 18ms/step - loss: 0.3853 - output_0_loss: 0.1630 - output_1_loss: 0.1561 - output_2_loss: 0.0662\n",
      "Epoch 77/1000\n",
      "24777/24777 [==============================] - 424s 17ms/step - loss: 0.3837 - output_0_loss: 0.1629 - output_1_loss: 0.1549 - output_2_loss: 0.0659\n",
      "Epoch 78/1000\n",
      "24777/24777 [==============================] - 432s 17ms/step - loss: 0.3819 - output_0_loss: 0.1625 - output_1_loss: 0.1540 - output_2_loss: 0.0654\n",
      "Epoch 79/1000\n",
      "24777/24777 [==============================] - 436s 18ms/step - loss: 0.3792 - output_0_loss: 0.1618 - output_1_loss: 0.1530 - output_2_loss: 0.0644\n",
      "Epoch 80/1000\n",
      "24777/24777 [==============================] - 435s 18ms/step - loss: 0.3784 - output_0_loss: 0.1611 - output_1_loss: 0.1527 - output_2_loss: 0.0646\n",
      "Epoch 81/1000\n",
      "24777/24777 [==============================] - 430s 17ms/step - loss: 0.3757 - output_0_loss: 0.1609 - output_1_loss: 0.1512 - output_2_loss: 0.0636\n",
      "Epoch 82/1000\n",
      "24777/24777 [==============================] - 443s 18ms/step - loss: 0.3748 - output_0_loss: 0.1603 - output_1_loss: 0.1510 - output_2_loss: 0.0635\n",
      "Epoch 83/1000\n",
      "24777/24777 [==============================] - 432s 17ms/step - loss: 0.3731 - output_0_loss: 0.1602 - output_1_loss: 0.1501 - output_2_loss: 0.0628\n",
      "Epoch 84/1000\n",
      "24777/24777 [==============================] - 434s 18ms/step - loss: 0.3707 - output_0_loss: 0.1595 - output_1_loss: 0.1492 - output_2_loss: 0.0619\n",
      "Epoch 85/1000\n",
      "20352/24777 [=======================>......] - ETA: 1:19 - loss: 0.3658 - output_0_loss: 0.1585 - output_1_loss: 0.1468 - output_2_loss: 0.0605"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-ec1f26756086>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mX_syllables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_syllables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_syllables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m ], [Y[0], Y[1], Y[2]], batch_size=64, epochs=1000)\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/haiku/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/miniconda3/envs/haiku/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/haiku/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/haiku/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/haiku/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit([\n",
    "    X[0], X[1], X[2],\n",
    "    X_syllables[:,0], X_syllables[:,1], X_syllables[:,2]\n",
    "], [Y[0], Y[1], Y[2]], batch_size=64, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "24777/24777 [==============================] - 354s 14ms/step - loss: 0.3664 - output_0_loss: 0.1586 - output_1_loss: 0.1469 - output_2_loss: 0.0608\n",
      "\n",
      "Epoch 00001: loss improved from -inf to 0.36639, saving model to weights-improvement-01-0.37.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/docmario/miniconda3/envs/haiku/lib/python3.6/site-packages/keras/engine/network.py:877: UserWarning: Layer lstm_0 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'syllable_dense_0/Relu:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'syllable_dense_0/Relu:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "/home/docmario/miniconda3/envs/haiku/lib/python3.6/site-packages/keras/engine/network.py:877: UserWarning: Layer lstm_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'add_h_1/add:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'add_c_1/add:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "/home/docmario/miniconda3/envs/haiku/lib/python3.6/site-packages/keras/engine/network.py:877: UserWarning: Layer lstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'add_h_2/add:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'add_c_2/add:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/1000\n",
      "24777/24777 [==============================] - 421s 17ms/step - loss: 0.3633 - output_0_loss: 0.1576 - output_1_loss: 0.1456 - output_2_loss: 0.0601\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.36639\n",
      "Epoch 3/1000\n",
      "24777/24777 [==============================] - 428s 17ms/step - loss: 0.3621 - output_0_loss: 0.1573 - output_1_loss: 0.1452 - output_2_loss: 0.0596\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.36639\n",
      "Epoch 4/1000\n",
      "24777/24777 [==============================] - 437s 18ms/step - loss: 0.3609 - output_0_loss: 0.1571 - output_1_loss: 0.1440 - output_2_loss: 0.0597\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.36639\n",
      "Epoch 5/1000\n",
      "24777/24777 [==============================] - 431s 17ms/step - loss: 0.3589 - output_0_loss: 0.1565 - output_1_loss: 0.1435 - output_2_loss: 0.0589\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.36639\n",
      "Epoch 6/1000\n",
      "24777/24777 [==============================] - 454s 18ms/step - loss: 0.3574 - output_0_loss: 0.1562 - output_1_loss: 0.1428 - output_2_loss: 0.0584\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.36639\n",
      "Epoch 7/1000\n",
      "24777/24777 [==============================] - 456s 18ms/step - loss: 0.3558 - output_0_loss: 0.1557 - output_1_loss: 0.1420 - output_2_loss: 0.0582\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.36639\n",
      "Epoch 8/1000\n",
      "24777/24777 [==============================] - 468s 19ms/step - loss: 0.3546 - output_0_loss: 0.1553 - output_1_loss: 0.1416 - output_2_loss: 0.0577\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.36639\n",
      "Epoch 9/1000\n",
      "24777/24777 [==============================] - 455s 18ms/step - loss: 0.3519 - output_0_loss: 0.1548 - output_1_loss: 0.1402 - output_2_loss: 0.0568\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.36639\n",
      "Epoch 10/1000\n",
      "24777/24777 [==============================] - 465s 19ms/step - loss: 0.3523 - output_0_loss: 0.1545 - output_1_loss: 0.1405 - output_2_loss: 0.0572\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.36639\n",
      "Epoch 11/1000\n",
      "24777/24777 [==============================] - 458s 18ms/step - loss: 0.3494 - output_0_loss: 0.1538 - output_1_loss: 0.1391 - output_2_loss: 0.0565\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.36639\n",
      "Epoch 12/1000\n",
      "24777/24777 [==============================] - 466s 19ms/step - loss: 0.3488 - output_0_loss: 0.1539 - output_1_loss: 0.1387 - output_2_loss: 0.0563\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.36639\n",
      "Epoch 13/1000\n",
      "24777/24777 [==============================] - 456s 18ms/step - loss: 0.3470 - output_0_loss: 0.1535 - output_1_loss: 0.1376 - output_2_loss: 0.0559\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.36639\n",
      "Epoch 14/1000\n",
      "24777/24777 [==============================] - 461s 19ms/step - loss: 0.3452 - output_0_loss: 0.1526 - output_1_loss: 0.1372 - output_2_loss: 0.0554\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.36639\n",
      "Epoch 15/1000\n",
      "24777/24777 [==============================] - 462s 19ms/step - loss: 0.3447 - output_0_loss: 0.1529 - output_1_loss: 0.1365 - output_2_loss: 0.0553\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.36639\n",
      "Epoch 16/1000\n",
      "24777/24777 [==============================] - 456s 18ms/step - loss: 0.3428 - output_0_loss: 0.1524 - output_1_loss: 0.1358 - output_2_loss: 0.0546\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.36639\n",
      "Epoch 17/1000\n",
      "24777/24777 [==============================] - 468s 19ms/step - loss: 0.3417 - output_0_loss: 0.1520 - output_1_loss: 0.1353 - output_2_loss: 0.0544\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.36639\n",
      "Epoch 18/1000\n",
      "24777/24777 [==============================] - 432s 17ms/step - loss: 0.3401 - output_0_loss: 0.1516 - output_1_loss: 0.1346 - output_2_loss: 0.0539\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.36639\n",
      "Epoch 19/1000\n",
      "24777/24777 [==============================] - 427s 17ms/step - loss: 0.3393 - output_0_loss: 0.1513 - output_1_loss: 0.1337 - output_2_loss: 0.0543\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.36639\n",
      "Epoch 20/1000\n",
      "24777/24777 [==============================] - 435s 18ms/step - loss: 0.3366 - output_0_loss: 0.1507 - output_1_loss: 0.1327 - output_2_loss: 0.0532\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.36639\n",
      "Epoch 21/1000\n",
      "24777/24777 [==============================] - 430s 17ms/step - loss: 0.3363 - output_0_loss: 0.1504 - output_1_loss: 0.1327 - output_2_loss: 0.0532\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.36639\n",
      "Epoch 22/1000\n",
      "24777/24777 [==============================] - 418s 17ms/step - loss: 0.3349 - output_0_loss: 0.1504 - output_1_loss: 0.1316 - output_2_loss: 0.0529\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.36639\n",
      "Epoch 23/1000\n",
      "24777/24777 [==============================] - 438s 18ms/step - loss: 0.3342 - output_0_loss: 0.1499 - output_1_loss: 0.1316 - output_2_loss: 0.0526\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.36639\n",
      "Epoch 24/1000\n",
      "24777/24777 [==============================] - 426s 17ms/step - loss: 0.3328 - output_0_loss: 0.1496 - output_1_loss: 0.1309 - output_2_loss: 0.0523\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.36639\n",
      "Epoch 25/1000\n",
      "24777/24777 [==============================] - 457s 18ms/step - loss: 0.3306 - output_0_loss: 0.1490 - output_1_loss: 0.1298 - output_2_loss: 0.0518\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.36639\n",
      "Epoch 26/1000\n",
      "24777/24777 [==============================] - 499s 20ms/step - loss: 0.3299 - output_0_loss: 0.1491 - output_1_loss: 0.1292 - output_2_loss: 0.0515\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.36639\n",
      "Epoch 27/1000\n",
      "24777/24777 [==============================] - 498s 20ms/step - loss: 0.3279 - output_0_loss: 0.1487 - output_1_loss: 0.1282 - output_2_loss: 0.0510\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.36639\n",
      "Epoch 28/1000\n",
      "24777/24777 [==============================] - 494s 20ms/step - loss: 0.3268 - output_0_loss: 0.1482 - output_1_loss: 0.1281 - output_2_loss: 0.0505\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.36639\n",
      "Epoch 29/1000\n",
      "24777/24777 [==============================] - 492s 20ms/step - loss: 0.3259 - output_0_loss: 0.1479 - output_1_loss: 0.1273 - output_2_loss: 0.0508\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.36639\n",
      "Epoch 30/1000\n",
      "24777/24777 [==============================] - 493s 20ms/step - loss: 0.3246 - output_0_loss: 0.1478 - output_1_loss: 0.1264 - output_2_loss: 0.0504\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.36639\n",
      "Epoch 31/1000\n",
      "24777/24777 [==============================] - 489s 20ms/step - loss: 0.3237 - output_0_loss: 0.1472 - output_1_loss: 0.1266 - output_2_loss: 0.0499\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.36639\n",
      "Epoch 32/1000\n",
      "24777/24777 [==============================] - 431s 17ms/step - loss: 0.3229 - output_0_loss: 0.1472 - output_1_loss: 0.1257 - output_2_loss: 0.0500\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.36639\n",
      "Epoch 33/1000\n",
      "24777/24777 [==============================] - 435s 18ms/step - loss: 0.3213 - output_0_loss: 0.1472 - output_1_loss: 0.1250 - output_2_loss: 0.0491\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.36639\n",
      "Epoch 34/1000\n",
      "24777/24777 [==============================] - 437s 18ms/step - loss: 0.3200 - output_0_loss: 0.1462 - output_1_loss: 0.1245 - output_2_loss: 0.0493\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.36639\n",
      "Epoch 35/1000\n",
      "24777/24777 [==============================] - 437s 18ms/step - loss: 0.3195 - output_0_loss: 0.1463 - output_1_loss: 0.1241 - output_2_loss: 0.0492\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.36639\n",
      "Epoch 36/1000\n",
      "24777/24777 [==============================] - 438s 18ms/step - loss: 0.3181 - output_0_loss: 0.1458 - output_1_loss: 0.1236 - output_2_loss: 0.0487\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.36639\n",
      "Epoch 37/1000\n",
      "24777/24777 [==============================] - 440s 18ms/step - loss: 0.3179 - output_0_loss: 0.1459 - output_1_loss: 0.1230 - output_2_loss: 0.0489\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.36639\n",
      "Epoch 38/1000\n",
      "24777/24777 [==============================] - 435s 18ms/step - loss: 0.3159 - output_0_loss: 0.1456 - output_1_loss: 0.1223 - output_2_loss: 0.0480\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.36639\n",
      "Epoch 39/1000\n",
      "24777/24777 [==============================] - 444s 18ms/step - loss: 0.3155 - output_0_loss: 0.1457 - output_1_loss: 0.1217 - output_2_loss: 0.0481\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.36639\n",
      "Epoch 40/1000\n",
      "24777/24777 [==============================] - 439s 18ms/step - loss: 0.3140 - output_0_loss: 0.1448 - output_1_loss: 0.1213 - output_2_loss: 0.0479\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.36639\n",
      "Epoch 41/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24777/24777 [==============================] - 444s 18ms/step - loss: 0.3136 - output_0_loss: 0.1447 - output_1_loss: 0.1212 - output_2_loss: 0.0478\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.36639\n",
      "Epoch 42/1000\n",
      "24777/24777 [==============================] - 438s 18ms/step - loss: 0.3127 - output_0_loss: 0.1444 - output_1_loss: 0.1205 - output_2_loss: 0.0478\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.36639\n",
      "Epoch 43/1000\n",
      "24777/24777 [==============================] - 460s 19ms/step - loss: 0.3117 - output_0_loss: 0.1440 - output_1_loss: 0.1203 - output_2_loss: 0.0474\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.36639\n",
      "Epoch 44/1000\n",
      "24777/24777 [==============================] - 467s 19ms/step - loss: 0.3100 - output_0_loss: 0.1440 - output_1_loss: 0.1195 - output_2_loss: 0.0465\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.36639\n",
      "Epoch 45/1000\n",
      "24777/24777 [==============================] - 436s 18ms/step - loss: 0.3079 - output_0_loss: 0.1435 - output_1_loss: 0.1180 - output_2_loss: 0.0464\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.36639\n",
      "Epoch 46/1000\n",
      "24777/24777 [==============================] - 436s 18ms/step - loss: 0.3081 - output_0_loss: 0.1434 - output_1_loss: 0.1181 - output_2_loss: 0.0466\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.36639\n",
      "Epoch 47/1000\n",
      "24777/24777 [==============================] - 439s 18ms/step - loss: 0.3066 - output_0_loss: 0.1429 - output_1_loss: 0.1175 - output_2_loss: 0.0461\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.36639\n",
      "Epoch 48/1000\n",
      "24777/24777 [==============================] - 433s 17ms/step - loss: 0.3059 - output_0_loss: 0.1427 - output_1_loss: 0.1170 - output_2_loss: 0.0462\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.36639\n",
      "Epoch 49/1000\n",
      "24777/24777 [==============================] - 460s 19ms/step - loss: 0.3054 - output_0_loss: 0.1430 - output_1_loss: 0.1170 - output_2_loss: 0.0455\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.36639\n",
      "Epoch 50/1000\n",
      "24777/24777 [==============================] - 447s 18ms/step - loss: 0.3040 - output_0_loss: 0.1426 - output_1_loss: 0.1159 - output_2_loss: 0.0455\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.36639\n",
      "Epoch 51/1000\n",
      "24777/24777 [==============================] - 448s 18ms/step - loss: 0.3044 - output_0_loss: 0.1423 - output_1_loss: 0.1164 - output_2_loss: 0.0456\n",
      "\n",
      "Epoch 00051: loss did not improve from 0.36639\n",
      "Epoch 52/1000\n",
      "24777/24777 [==============================] - 465s 19ms/step - loss: 0.3023 - output_0_loss: 0.1417 - output_1_loss: 0.1153 - output_2_loss: 0.0453\n",
      "\n",
      "Epoch 00052: loss did not improve from 0.36639\n",
      "Epoch 53/1000\n",
      "24777/24777 [==============================] - 454s 18ms/step - loss: 0.3012 - output_0_loss: 0.1416 - output_1_loss: 0.1145 - output_2_loss: 0.0451\n",
      "\n",
      "Epoch 00053: loss did not improve from 0.36639\n",
      "Epoch 54/1000\n",
      "24777/24777 [==============================] - 430s 17ms/step - loss: 0.3011 - output_0_loss: 0.1416 - output_1_loss: 0.1148 - output_2_loss: 0.0447\n",
      "\n",
      "Epoch 00054: loss did not improve from 0.36639\n",
      "Epoch 55/1000\n",
      "24777/24777 [==============================] - 425s 17ms/step - loss: 0.2989 - output_0_loss: 0.1409 - output_1_loss: 0.1133 - output_2_loss: 0.0447\n",
      "\n",
      "Epoch 00055: loss did not improve from 0.36639\n",
      "Epoch 56/1000\n",
      "24777/24777 [==============================] - 427s 17ms/step - loss: 0.2978 - output_0_loss: 0.1406 - output_1_loss: 0.1129 - output_2_loss: 0.0443\n",
      "\n",
      "Epoch 00056: loss did not improve from 0.36639\n",
      "Epoch 57/1000\n",
      "24777/24777 [==============================] - 436s 18ms/step - loss: 0.2980 - output_0_loss: 0.1406 - output_1_loss: 0.1131 - output_2_loss: 0.0443\n",
      "\n",
      "Epoch 00057: loss did not improve from 0.36639\n",
      "Epoch 58/1000\n",
      "24777/24777 [==============================] - 419s 17ms/step - loss: 0.2961 - output_0_loss: 0.1404 - output_1_loss: 0.1121 - output_2_loss: 0.0436\n",
      "\n",
      "Epoch 00058: loss did not improve from 0.36639\n",
      "Epoch 59/1000\n",
      "24777/24777 [==============================] - 431s 17ms/step - loss: 0.2958 - output_0_loss: 0.1402 - output_1_loss: 0.1118 - output_2_loss: 0.0438\n",
      "\n",
      "Epoch 00059: loss did not improve from 0.36639\n",
      "Epoch 60/1000\n",
      "24777/24777 [==============================] - 426s 17ms/step - loss: 0.2949 - output_0_loss: 0.1400 - output_1_loss: 0.1113 - output_2_loss: 0.0437\n",
      "\n",
      "Epoch 00060: loss did not improve from 0.36639\n",
      "Epoch 61/1000\n",
      "24777/24777 [==============================] - 444s 18ms/step - loss: 0.2940 - output_0_loss: 0.1397 - output_1_loss: 0.1109 - output_2_loss: 0.0434\n",
      "\n",
      "Epoch 00061: loss did not improve from 0.36639\n",
      "Epoch 62/1000\n",
      "24777/24777 [==============================] - 429s 17ms/step - loss: 0.2935 - output_0_loss: 0.1399 - output_1_loss: 0.1104 - output_2_loss: 0.0432\n",
      "\n",
      "Epoch 00062: loss did not improve from 0.36639\n",
      "Epoch 63/1000\n",
      "24777/24777 [==============================] - 425s 17ms/step - loss: 0.2925 - output_0_loss: 0.1395 - output_1_loss: 0.1099 - output_2_loss: 0.0431\n",
      "\n",
      "Epoch 00063: loss did not improve from 0.36639\n",
      "Epoch 64/1000\n",
      "24777/24777 [==============================] - 438s 18ms/step - loss: 0.2909 - output_0_loss: 0.1392 - output_1_loss: 0.1091 - output_2_loss: 0.0426\n",
      "\n",
      "Epoch 00064: loss did not improve from 0.36639\n",
      "Epoch 65/1000\n",
      "24777/24777 [==============================] - 427s 17ms/step - loss: 0.2908 - output_0_loss: 0.1392 - output_1_loss: 0.1093 - output_2_loss: 0.0423\n",
      "\n",
      "Epoch 00065: loss did not improve from 0.36639\n",
      "Epoch 66/1000\n",
      "10176/24777 [===========>..................] - ETA: 4:18 - loss: 0.2787 - output_0_loss: 0.1351 - output_1_loss: 0.1038 - output_2_loss: 0.0397"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-1685e06c7995>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mX_syllables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_syllables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_syllables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m ], [Y[0], Y[1], Y[2]], batch_size=64, epochs=1000, callbacks=callbacks_list)\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/haiku/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/miniconda3/envs/haiku/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/haiku/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/haiku/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/haiku/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "# Fit the model\n",
    "model.fit([\n",
    "    X[0], X[1], X[2],\n",
    "    X_syllables[:,0], X_syllables[:,1], X_syllables[:,2]\n",
    "], [Y[0], Y[1], Y[2]], batch_size=64, epochs=1000, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/docmario/miniconda3/envs/haiku/lib/python3.6/site-packages/keras/engine/network.py:877: UserWarning: Layer lstm_0 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'syllable_dense_0/Relu:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'syllable_dense_0/Relu:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "/home/docmario/miniconda3/envs/haiku/lib/python3.6/site-packages/keras/engine/network.py:877: UserWarning: Layer lstm_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'add_h_1/add:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'add_c_1/add:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "/home/docmario/miniconda3/envs/haiku/lib/python3.6/site-packages/keras/engine/network.py:877: UserWarning: Layer lstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'add_h_2/add:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'add_c_2/add:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    }
   ],
   "source": [
    "model.save('model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "generator_syllables_0 (InputLay (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "generator_in_h_0 (InputLayer)   (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "generator_syllable_dense_0 (Den (None, 512)          1024        generator_syllables_0[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "generator_in_c_0 (InputLayer)   (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "generator_input_0 (InputLayer)  (None, None, 64)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "generator_add_h_0 (Add)         (None, 512)          0           generator_in_h_0[0][0]           \n",
      "                                                                 generator_syllable_dense_0[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "generator_add_c_0 (Add)         (None, 512)          0           generator_in_c_0[0][0]           \n",
      "                                                                 generator_syllable_dense_0[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "generator_lstm_0 (LSTM)         [(None, None, 512),  1181696     generator_input_0[0][0]          \n",
      "                                                                 generator_add_h_0[0][0]          \n",
      "                                                                 generator_add_c_0[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, None, 64)     32832       generator_lstm_0[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 1,215,552\n",
      "Trainable params: 1,215,552\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator_inputs = [Input(shape=(None, n_tokens), name='generator_input_%s' % i) for i in range(3)]\n",
    "generator_inputs_h = [Input(shape=(latent_dim,), name='generator_in_h_%s' % i) for i in range(3)]\n",
    "generator_inputs_c = [Input(shape=(latent_dim,), name='generator_in_c_%s' % i) for i in range(3)]\n",
    "generator_lstms = [LSTM(latent_dim, return_state=True, return_sequences=True, name='generator_lstm_%s' % i) for i in range(3)]\n",
    "generator_lstm_out, generator_lstm_h, generator_lstm_c = [None, None, None], [None, None, None], [None, None, None]\n",
    "generator_denses = [Dense(n_tokens, activation='softmax') for i in range(3)]\n",
    "\n",
    "generator_syllables = [Input(shape=(1,), name='generator_syllables_%s' % i) for i in range(3)]\n",
    "generator_syllable_denses = [Dense(latent_dim, activation='relu', name='generator_syllable_dense_%s' % i) for i in range(3)]\n",
    "#syllable_dense_outputs = [syllable_denses[i](syllables[i]) for i in range(3)]\n",
    "\n",
    "generator_syllable_dense_outputs = []\n",
    "generator_outputs = []\n",
    "generator_models = []\n",
    "\n",
    "for i in range(3):\n",
    "    generator_syllable_dense_outputs.append(generator_syllable_denses[i](generator_syllables[i]))\n",
    "    generator_lstm_out[i], generator_lstm_h[i], generator_lstm_c[i] = generator_lstms[i](\n",
    "        generator_inputs[i], initial_state=[\n",
    "            Add(name='generator_add_h_%s' % i)([\n",
    "                generator_inputs_h[i],\n",
    "                generator_syllable_dense_outputs[i]\n",
    "            ]),\n",
    "            Add(name='generator_add_c_%s' % i)([\n",
    "                generator_inputs_c[i],\n",
    "                generator_syllable_dense_outputs[i]\n",
    "            ])\n",
    "        ]\n",
    "    )\n",
    "    generator_outputs.append(generator_denses[i](generator_lstm_out[i]))\n",
    "\n",
    "    generator_models.append(Model(\n",
    "        [generator_inputs[i], generator_syllables[i], generator_inputs_h[i], generator_inputs_c[i]],\n",
    "        [generator_outputs[i], generator_lstm_h[i], generator_lstm_c[i]]\n",
    "    ))\n",
    "\n",
    "    generator_syllable_denses[i].set_weights(syllable_denses[i].get_weights())\n",
    "    generator_lstms[i].set_weights(lstms[i].get_weights())\n",
    "    generator_denses[i].set_weights(denses[i].get_weights())\n",
    "\n",
    "'''# Hook up line 0\n",
    "generator_syllable_dense_outputs = [generator_syllable_denses[0](generator_syllables[0])]\n",
    "generator_lstm_out[0], generator_lstm_h[0], generator_lstm_c[0] = generator_lstms[0](\n",
    "    generator_inputs[0], initial_state=[generator_syllable_dense_outputs[0], generator_syllable_dense_outputs[0]]\n",
    ")\n",
    "generator_outputs = [generator_denses[0](generator_lstm_out[0])]\n",
    "generator_models = [Model([generator_inputs[0], generator_syllables[0]], [generator_outputs[0], generator_lstm_h[0], generator_lstm_c[0]])]\n",
    "\n",
    "# Set weights for line 0\n",
    "generator_syllable_denses[0].set_weights(syllable_denses[0].get_weights())\n",
    "generator_lstms[0].set_weights(lstms[0].get_weights())\n",
    "generator_denses[0].set_weights(denses[0].get_weights())'''\n",
    "\n",
    "generator_models[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "fgenerator_input_0 (InputLayer) (None, None, 64)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "fgenerator_in_h_0 (InputLayer)  (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "fgenerator_in_c_0 (InputLayer)  (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "fgenerator_lstm_0 (LSTM)        [(None, None, 512),  1181696     fgenerator_input_0[0][0]         \n",
      "                                                                 fgenerator_in_h_0[0][0]          \n",
      "                                                                 fgenerator_in_c_0[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, None, 64)     32832       fgenerator_lstm_0[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 1,214,528\n",
      "Trainable params: 1,214,528\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fgenerator_inputs = [Input(shape=(None, n_tokens), name='fgenerator_input_%s' % i) for i in range(3)]\n",
    "fgenerator_inputs_h = [Input(shape=(latent_dim,), name='fgenerator_in_h_%s' % i) for i in range(3)]\n",
    "fgenerator_inputs_c = [Input(shape=(latent_dim,), name='fgenerator_in_c_%s' % i) for i in range(3)]\n",
    "fgenerator_lstms = [LSTM(latent_dim, return_state=True, return_sequences=True, name='fgenerator_lstm_%s' % i) for i in range(3)]\n",
    "fgenerator_lstm_out, fgenerator_lstm_h, fgenerator_lstm_c = [None, None, None], [None, None, None], [None, None, None]\n",
    "fgenerator_denses = [Dense(n_tokens, activation='softmax') for i in range(3)]\n",
    "\n",
    "#fgenerator_syllables = [Input(shape=(1,), name='fgenerator_syllables_%s' % i) for i in range(3)]\n",
    "#fgenerator_syllable_denses = [Dense(latent_dim, activation='relu', name='fgenerator_syllable_dense_%s' % i) for i in range(3)]\n",
    "\n",
    "#fgenerator_syllable_dense_outputs = []\n",
    "fgenerator_outputs = []\n",
    "fgenerator_models = []\n",
    "\n",
    "for i in range(3):\n",
    "    #fgenerator_syllable_dense_outputs.append(fgenerator_syllable_denses[i](fgenerator_syllables[i]))\n",
    "    fgenerator_lstm_out[i], fgenerator_lstm_h[i], fgenerator_lstm_c[i] = fgenerator_lstms[i](\n",
    "        fgenerator_inputs[i], initial_state=[fgenerator_inputs_h[i], fgenerator_inputs_c[i]]\n",
    "        \n",
    "    )\n",
    "    fgenerator_outputs.append(fgenerator_denses[i](fgenerator_lstm_out[i]))\n",
    "\n",
    "    fgenerator_models.append(Model(\n",
    "        [fgenerator_inputs[i], fgenerator_inputs_h[i], fgenerator_inputs_c[i]],\n",
    "        [fgenerator_outputs[i], fgenerator_lstm_h[i], fgenerator_lstm_c[i]]\n",
    "    ))\n",
    "\n",
    "    #generator_syllable_denses[i].set_weights(syllable_denses[i].get_weights())\n",
    "    fgenerator_lstms[i].set_weights(lstms[i].get_weights())\n",
    "    fgenerator_denses[i].set_weights(denses[i].get_weights())\n",
    "\n",
    "fgenerator_models[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/docmario/miniconda3/envs/haiku/lib/python3.6/site-packages/keras/engine/network.py:877: UserWarning: Layer fgenerator_lstm_0 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'fgenerator_in_h_0_2:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'fgenerator_in_c_0_2:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    }
   ],
   "source": [
    "fgenerator_models[0].save('fgenerator_model0.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parking lot at dawn?\n",
      "jumpiding despite on                                               a\n",
      "never sallaty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/docmario/miniconda3/envs/haiku/lib/python3.6/site-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "h,c = np.zeros(latent_dim).reshape((1,-1)), np.zeros(latent_dim).reshape((1,-1))\n",
    "#first = 'maw'\n",
    "pattern = [5,7,5]\n",
    "#generator_models[0].reset_states()\n",
    "#generator_lstms[0].reset_states()\n",
    "for i,syllables in enumerate(pattern):\n",
    "    #line = [random.randint(2,21)]\n",
    "    if i == 0:\n",
    "        line = [random.randint(2,21)]\n",
    "    else:\n",
    "        if 1 in line:\n",
    "            line = [line[line.index(1)-1]]\n",
    "        else:\n",
    "            line = [line[-1]]\n",
    "    #line = t.texts_to_sequences(first[i])[0]\n",
    "    #print(line)\n",
    "    \n",
    "    ## FIRST CHAR\n",
    "    def f():\n",
    "        while True:\n",
    "            yield [np_utils.to_categorical(line[-1], num_classes=n_tokens).reshape((1,1,-1)), np.array([syllables]), h, c]\n",
    "    \n",
    "    character, h, c = generator_models[i].predict_generator(f(), steps=1)    \n",
    "    line.append(np.argmax(character))\n",
    "    \n",
    "    ## ALL THE REST (Don't include syllables, use fgenerator)\n",
    "    def f():\n",
    "        while True:\n",
    "            yield [np_utils.to_categorical(line[-1], num_classes=n_tokens).reshape((1,1,-1)), h, c]\n",
    "            \n",
    "    # While less than the max length and the last character isn't the line terminator\n",
    "    while (len(line) < max_line_len):# and (line[-1] != 1):\n",
    "        character, h, c = fgenerator_models[i].predict_generator(f(), steps=1)\n",
    "        #line.append(np.argmax(character))\n",
    "        \n",
    "        \n",
    "        line.append(sample(character[0][0], .3))\n",
    "        #print (np.argmax(character), line[-1])\n",
    "        \n",
    "    #print(line[1:line.index(1)])\n",
    "    #print(line)\n",
    "    text = t.sequences_to_texts([line])[0].strip()[1:].replace('   ', '\\n').replace(' ', '').replace('\\n', ' ')\n",
    "    #print(text[1:])\n",
    "    print(text)\n",
    "    #if 1 in line:\n",
    "    #    #print(t.sequences_to_texts([line[1:line.index(1)]]))\n",
    "    #else:\n",
    "    #    #print(t.sequences_to_texts([line[1:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4,\n",
       " 4,\n",
       " 11,\n",
       " 3,\n",
       " 2,\n",
       " 22,\n",
       " 10,\n",
       " 3,\n",
       " 5,\n",
       " 23,\n",
       " 2,\n",
       " 5,\n",
       " 8,\n",
       " 13,\n",
       " 2,\n",
       " 4,\n",
       " 11,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 15,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line[line.index(1)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('\\n', 1176567),\n",
       " (' ', 91088),\n",
       " ('e', 70913),\n",
       " ('t', 56983),\n",
       " ('a', 49723),\n",
       " ('s', 49409),\n",
       " ('o', 47840),\n",
       " ('n', 45498),\n",
       " ('i', 44011),\n",
       " ('r', 41508),\n",
       " ('h', 34613),\n",
       " ('l', 29824),\n",
       " ('d', 22763),\n",
       " ('m', 18905),\n",
       " ('g', 18866),\n",
       " ('f', 17798),\n",
       " ('c', 17475),\n",
       " ('u', 16137),\n",
       " ('w', 16076),\n",
       " ('p', 12694),\n",
       " ('b', 11695),\n",
       " ('y', 10017),\n",
       " ('k', 6938),\n",
       " ('-', 4682),\n",
       " ('v', 4642),\n",
       " ('.', 4179),\n",
       " (\"'\", 2211),\n",
       " ('?', 1459),\n",
       " ('z', 964),\n",
       " ('j', 822),\n",
       " ('q', 540),\n",
       " ('x', 503),\n",
       " (',', 317),\n",
       " (':', 122),\n",
       " ('\"', 67),\n",
       " ('~', 61),\n",
       " ('!', 59),\n",
       " ('1', 57),\n",
       " (';', 47),\n",
       " ('2', 45),\n",
       " ('>', 38),\n",
       " ('0', 35),\n",
       " ('<', 30),\n",
       " ('3', 28),\n",
       " ('&', 21),\n",
       " ('4', 19),\n",
       " ('7', 17),\n",
       " ('6', 14),\n",
       " ('5', 14),\n",
       " ('9', 14),\n",
       " ('8', 13),\n",
       " ('Ã©', 6),\n",
       " ('*', 5),\n",
       " ('/', 5),\n",
       " ('(', 3),\n",
       " ('\\xa0', 2),\n",
       " ('[', 2),\n",
       " ('=', 1),\n",
       " ('Ã¤', 1),\n",
       " (']', 1),\n",
       " (')', 1)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(t.word_counts.items()), key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['m',\n",
       " 'e',\n",
       " 'o',\n",
       " 'r',\n",
       " 'i',\n",
       " 'a',\n",
       " 'l',\n",
       " ' ',\n",
       " 'd',\n",
       " 'y',\n",
       " '-',\n",
       " '\\n',\n",
       " 's',\n",
       " 'h',\n",
       " 'w',\n",
       " 'f',\n",
       " 'c',\n",
       " 't',\n",
       " 'p',\n",
       " 'n',\n",
       " 'g',\n",
       " 'k',\n",
       " 'b',\n",
       " 'u',\n",
       " 'x',\n",
       " 'q',\n",
       " 'v',\n",
       " 'z',\n",
       " '~',\n",
       " \"'\",\n",
       " '.',\n",
       " 'j',\n",
       " ',',\n",
       " '!',\n",
       " '<',\n",
       " '>',\n",
       " '?',\n",
       " ':',\n",
       " '2',\n",
       " '1',\n",
       " '*',\n",
       " '7',\n",
       " '3',\n",
       " '0',\n",
       " ';',\n",
       " '6',\n",
       " '5',\n",
       " '8',\n",
       " '&',\n",
       " 'Ã©',\n",
       " '\"',\n",
       " '9',\n",
       " '4',\n",
       " '(',\n",
       " '=',\n",
       " 'Ã¤',\n",
       " '\\xa0',\n",
       " '[',\n",
       " ']',\n",
       " '/',\n",
       " ')']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(t.word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
